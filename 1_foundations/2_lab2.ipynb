{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to the Second Lab - Week 1, Day 3\n",
    "\n",
    "Today we will work with lots of models! This is a way to get comfortable with APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Important point - please read</h2>\n",
    "            <span style=\"color:#ff7800;\">The way I collaborate with you may be different to other courses you've taken. I prefer not to type code while you watch. Rather, I execute Jupyter Labs, like this, and give you an intuition for what's going on. My suggestion is that you carefully execute this yourself, <b>after</b> watching the lecture. Add print statements to understand what's going on, and then come up with your own variations.<br/><br/>If you have time, I'd love it if you submit a PR for changes in the community_contributions folder - instructions in the resources. Also, if you have a Github account, use this to showcase your variations. Not only is this essential practice, but it demonstrates your skills to others, including perhaps future clients or employers...\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with imports - ask ChatGPT to explain any package that you don't know\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Always remember to do this!\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key exists and begins sk-ant-\n",
      "Google API Key not set (and this is optional)\n",
      "DeepSeek API Key exists and begins sk-\n",
      "Groq API Key exists and begins gsk_\n"
     ]
    }
   ],
   "source": [
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set (and this is optional)\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:2]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set (and this is optional)\")\n",
    "\n",
    "if deepseek_api_key:\n",
    "    print(f\"DeepSeek API Key exists and begins {deepseek_api_key[:3]}\")\n",
    "else:\n",
    "    print(\"DeepSeek API Key not set (and this is optional)\")\n",
    "\n",
    "if groq_api_key:\n",
    "    print(f\"Groq API Key exists and begins {groq_api_key[:4]}\")\n",
    "else:\n",
    "    print(\"Groq API Key not set (and this is optional)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = \"Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. \"\n",
    "request += \"Answer only with the question, no explanation.\"\n",
    "messages = [{\"role\": \"user\", \"content\": request}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. Answer only with the question, no explanation.'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Designing an ethical framework for artificial intelligence (AI) that balances innovation and safety is a complex task. Here are key principles I would prioritize, along with strategies for addressing potential conflicts between them:\n",
      "\n",
      "### Key Principles\n",
      "\n",
      "1. **Transparency**:\n",
      "   - **Description**: AI systems should be able to explain their decisions and underlying processes.\n",
      "   - **Conflict Resolution**: In situations where transparency affects proprietary technology (e.g., trade secrets), a balanced approach can involve sharing enough information to ensure accountability while protecting intellectual property.\n",
      "\n",
      "2. **Accountability**:\n",
      "   - **Description**: Clear lines of accountability should exist for AI systems, including consequences for misuse or harm.\n",
      "   - **Conflict Resolution**: Establishing regulatory bodies that oversee AI deployment can help enforce accountability, even when innovation is challenged by strict regulations.\n",
      "\n",
      "3. **Fairness**:\n",
      "   - **Description**: AI systems should be designed to prevent discrimination and bias.\n",
      "   - **Conflict Resolution**: Implement metrics to assess fairness during development, and create feedback loops that allow adjustments based on real-world performance.\n",
      "\n",
      "4. **Safety and Reliability**:\n",
      "   - **Description**: AI systems must be safe for users and reliable in their performance.\n",
      "   - **Conflict Resolution**: Employ rigorous testing protocols and simulations to ensure safety, while maintaining an iterative approach to innovation that allows for rapid prototyping.\n",
      "\n",
      "5. **Privacy**:\n",
      "   - **Description**: Safeguarding users' data and respecting their privacy rights is paramount.\n",
      "   - **Conflict Resolution**: Introduce data minimization and anonymization techniques, allowing for innovation through data analysis without compromising individual privacy.\n",
      "\n",
      "6. **Inclusivity**:\n",
      "   - **Description**: AI development should consider the needs of diverse communities to ensure that benefits are widely accessible.\n",
      "   - **Conflict Resolution**: In cases where certain innovations may inadvertently exclude groups, engage in participatory design processes that involve underrepresented communities.\n",
      "\n",
      "7. **Non-maleficence**:\n",
      "   - **Description**: AI should not cause harm and should enhance human welfare.\n",
      "   - **Conflict Resolution**: Set up ethical review boards that assess the potential risks and benefits of AI technologies before they are deployed.\n",
      "\n",
      "8. **Sustainability**:\n",
      "   - **Description**: AI should contribute to sustainable development goals and consider environmental impacts.\n",
      "   - **Conflict Resolution**: Innovate in energy-efficient algorithms and systems that not only advance technology but do so in an environmentally friendly manner.\n",
      "\n",
      "### Addressing Conflicts\n",
      "\n",
      "1. **Stakeholder Engagement**: Collaborate with a diverse set of stakeholders—including ethicists, industry leaders, affected communities, and policymakers—to gauge perspectives on innovation versus safety. This can help build consensus on priorities.\n",
      "\n",
      "2. **Risk Assessment Frameworks**: Develop comprehensive frameworks that evaluate both the potential risks and benefits associated with new technologies. This framework could help prioritize safety while fostering innovation.\n",
      "\n",
      "3. **Ethical Audits and Assessments**: Establish regular audits of AI systems to evaluate their adherence to ethical principles. This can help ensure compliance and identify areas where trade-offs between innovation and safety may need to occur.\n",
      "\n",
      "4. **Phased Implementation**: Encourage a phased approach to deploying AI technologies, allowing for real-world testing and adjustments based on feedback before full-scale launch.\n",
      "\n",
      "5. **Adaptive Regulation**: Advocate for regulations that can evolve with emerging technologies. Adaptive frameworks can accommodate innovative approaches while safeguarding public interests.\n",
      "\n",
      "6. **Public Accountability Mechanisms**: Create avenues for public oversight and accountability, such as independent watchdogs or consumer advocacy groups, which can raise concerns when innovation comes at the cost of safety or ethical considerations.\n",
      "\n",
      "By prioritizing these principles and proactively planning for conflict resolution, the ethical framework could foster a balanced environment where innovation can thrive while ensuring that safety and ethical considerations remain central to AI development and deployment.\n"
     ]
    }
   ],
   "source": [
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    ")\n",
    "question = response.choices[0].message.content\n",
    "print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitors = []\n",
    "answers = []\n",
    "messages = [{\"role\": \"user\", \"content\": question}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Your outline for an ethical framework for artificial intelligence (AI) is comprehensive and addresses many of the pressing issues in the field today. Here are some additional thoughts and elaborations on the principles, as well as strategies to enhance the balance between innovation and safety.\n",
       "\n",
       "### Additional Considerations\n",
       "\n",
       "#### 1. **Interdisciplinary Collaboration**:\n",
       "   - **Description**: Engaging experts from various fields (e.g., computer science, ethics, sociology, law) to inform AI development and policies.\n",
       "   - **Implementation Strategy**: Form interdisciplinary panels that regularly convene to discuss and evaluate the implications of AI technologies, ensuring diverse perspectives are represented.\n",
       "\n",
       "#### 2. **User-Centric Design**:\n",
       "   - **Description**: AI systems should prioritize user experience and needs, ensuring they are intuitive and beneficial.\n",
       "   - **Implementation Strategy**: Engage end-users throughout the development process through usability testing and feedback sessions, ensuring that the system aligns with user needs while maintaining ethical standards.\n",
       "\n",
       "#### 3. **Continuous Learning and Adaptation**:\n",
       "   - **Description**: AI systems should be designed to learn from their environment and user interactions continuously.\n",
       "   - **Conflict Resolution**: Develop robust mechanisms to monitor AI learning processes and set thresholds for intervention when ethical guidelines may be breached or unintended consequences arise.\n",
       "\n",
       "### Expanding Conflict Resolution Strategies\n",
       "\n",
       "#### 1. **Ethical Training Programs**:\n",
       "   - **Description**: Create training programs for AI developers and stakeholders focused on ethical considerations in AI.\n",
       "   - **Implementation**: Mandatory ethics training that includes case studies of past AI challenges, fostering a culture of ethical awareness in tech companies.\n",
       "\n",
       "#### 2. **Stakeholder Reporting Channels**:\n",
       "   - **Description**: Create formal channels where stakeholders can report ethical concerns or suggest improvements.\n",
       "   - **Implementation**: Use anonymous reporting, ensuring that whistleblowers can express concerns without fear of repercussions, thus promoting an environment of accountability.\n",
       "\n",
       "#### 3. **Prototyping Ethical Use Cases**:\n",
       "   - **Description**: Develop specific use cases that navigate ethical dilemmas while exploring innovative solutions.\n",
       "   - **Implementation**: Collaborate with academic institutions to run pilot projects that test ethical frameworks in practice, leading to actionable insights.\n",
       "\n",
       "### Enhancing Governance Structures\n",
       "\n",
       "1. **Public and Private Partnership Initiatives**:\n",
       "   - Foster partnerships that engage government agencies, research institutions, and private companies to co-create standards and best practices for ethical AI deployment.\n",
       "\n",
       "2. **International Cooperation**:\n",
       "   - Given AI's global implications, various nations should work together to create harmonized regulations and ethical standards, preventing a \"race to the bottom\" in ethical considerations.\n",
       "\n",
       "3. **Reflective Buffers**:\n",
       "   - Design systems with layered reviews, where significant AI developments pass through different levels of ethical oversight to assess the impact before full implementation. This buffer can slow down potential innovations that may pose significant ethical dilemmas.\n",
       "\n",
       "### Conclusion\n",
       "\n",
       "The development of an ethical framework for artificial intelligence requires a dynamic and evolving approach that maintains a delicate balance between fostering innovation and ensuring safety and ethical compliance. By incorporating these additional considerations—like interdisciplinary collaboration and user-centric design—while enhancing conflict resolution strategies and governance structures, we can create an environment that promotes responsible AI development.\n",
       "\n",
       "Such a comprehensive framework not only prioritizes ethical integrity but also encourages public trust in AI technologies, ultimately leading to more sustainable and equitable solutions in various aspects of society."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The API we know well\n",
    "\n",
    "model_name = \"gpt-4o-mini\"\n",
    "\n",
    "response = openai.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "You've created a comprehensive ethical framework for AI that thoughtfully balances innovation with safety concerns. Your approach is particularly strong in how it:\n",
       "\n",
       "1. Addresses potential conflicts between principles directly, rather than simply listing ideals\n",
       "2. Proposes specific mechanisms (like ethical review boards and stakeholder engagement) rather than just abstract values\n",
       "3. Recognizes the tension between transparency and intellectual property protection\n",
       "4. Incorporates sustainability as a core principle, which is increasingly important\n",
       "\n",
       "One aspect you might consider strengthening is addressing the challenge of global governance across different cultural and legal frameworks. AI development happens internationally, and ethical standards vary across regions, creating potential for regulatory arbitrage where companies might operate in less regulated environments.\n",
       "\n",
       "Your suggestion for adaptive regulation is particularly insightful, as it acknowledges the rapid pace of AI development while maintaining safety guardrails. The phased implementation approach also offers a practical middle ground between unchecked innovation and excessive caution.\n",
       "\n",
       "Overall, your framework demonstrates sophisticated thinking about the complex interplay between technical advancement and ethical responsibility."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Anthropic has a slightly different API, and Max Tokens is required\n",
    "\n",
    "model_name = \"claude-3-7-sonnet-latest\"\n",
    "\n",
    "claude = Anthropic()\n",
    "response = claude.messages.create(model=model_name, messages=messages, max_tokens=1000)\n",
    "answer = response.content[0].text\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini = OpenAI(api_key=google_api_key, base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
    "model_name = \"gemini-2.0-flash\"\n",
    "\n",
    "response = gemini.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "APIStatusError",
     "evalue": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAPIStatusError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m deepseek = OpenAI(api_key=deepseek_api_key, base_url=\u001b[33m\"\u001b[39m\u001b[33mhttps://api.deepseek.com/v1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33mdeepseek-chat\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m response = \u001b[43mdeepseek\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m answer = response.choices[\u001b[32m0\u001b[39m].message.content\n\u001b[32m      7\u001b[39m display(Markdown(answer))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\progr\\Box\\machine_learning_test_lab\\AI_agent_engineering\\ai_agents\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\progr\\Box\\machine_learning_test_lab\\AI_agent_engineering\\ai_agents\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:925\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    882\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    883\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    884\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    922\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    923\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    924\u001b[39m     validate_response_format(response_format)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\progr\\Box\\machine_learning_test_lab\\AI_agent_engineering\\ai_agents\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1239\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1225\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1226\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1227\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1234\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1235\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1236\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1237\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1238\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1239\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\progr\\Box\\machine_learning_test_lab\\AI_agent_engineering\\ai_agents\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1034\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1031\u001b[39m             err.response.read()\n\u001b[32m   1033\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1034\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1036\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1038\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAPIStatusError\u001b[39m: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
     ]
    }
   ],
   "source": [
    "deepseek = OpenAI(api_key=deepseek_api_key, base_url=\"https://api.deepseek.com/v1\")\n",
    "model_name = \"deepseek-chat\"\n",
    "\n",
    "response = deepseek.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Designing an ethical framework for artificial intelligence (AI) that balances innovation and safety requires a multidimensional approach. The key principles outlined—transparency, accountability, fairness, safety and reliability, privacy, inclusivity, non-maleficence, and sustainability—provide a comprehensive foundation for addressing the complexities of AI development and deployment. Each principle is crucial and plays a role in ensuring that AI systems are not only innovative but also safe and ethically sound.\n",
       "\n",
       "### Balancing Innovation and Safety\n",
       "\n",
       "Balancing innovation and safety in AI development involves several strategies:\n",
       "\n",
       "1. **Regulatory Frameworks**: Establishing adaptive regulatory frameworks that can evolve with emerging technologies is essential. These frameworks should be flexible enough to accommodate innovation while safeguarding public interests.\n",
       "\n",
       "2. **Stakeholder Engagement**: Engaging with a diverse set of stakeholders, including ethicists, industry leaders, affected communities, and policymakers, can help build consensus on priorities and ensure that both innovation and safety are considered.\n",
       "\n",
       "3. **Risk Assessment and Management**: Developing comprehensive risk assessment frameworks that evaluate both the potential risks and benefits associated with new technologies can help prioritize safety while fostering innovation.\n",
       "\n",
       "4. **Phased Implementation**: Implementing AI technologies in a phased manner allows for real-world testing and adjustments based on feedback before full-scale launch, mitigating potential risks.\n",
       "\n",
       "5. **Continuous Monitoring and Evaluation**: Regular ethical audits and assessments of AI systems can help ensure compliance with ethical principles and identify areas where trade-offs between innovation and safety may need to occur.\n",
       "\n",
       "### Implementing the Ethical Framework\n",
       "\n",
       "Implementing the proposed ethical framework requires a structured approach:\n",
       "\n",
       "1. **Education and Training**: Providing education and training on ethical AI development and deployment for developers, policymakers, and users can ensure a wide understanding of the importance of balancing innovation and safety.\n",
       "\n",
       "2. **Incentivizing Ethical Practices**: Incentivizing companies and developers to adopt ethical practices through recognition, funding, or tax benefits can encourage the development of safe and ethical AI systems.\n",
       "\n",
       "3. **International Cooperation**: Encouraging international cooperation and agreements on AI ethics can help establish global standards and guidelines, ensuring that AI development and deployment are aligned with human values worldwide.\n",
       "\n",
       "4. **Public Awareness and Engagement**: Raising public awareness about the importance of ethical AI and engaging the public in discussions about AI ethics can foster a societal expectation for safe and ethical AI technologies.\n",
       "\n",
       "5. **Continuous Review and Update**: Regularly reviewing and updating the ethical framework to reflect new challenges and opportunities in AI development can ensure that it remains relevant and effective.\n",
       "\n",
       "By prioritizing these principles and strategies, it is possible to create an ethical framework for AI that supports innovation while ensuring safety and adherence to ethical standards. This balanced approach is essential for the responsible development and deployment of AI technologies that can benefit society as a whole."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "groq = OpenAI(api_key=groq_api_key, base_url=\"https://api.groq.com/openai/v1\")\n",
    "model_name = \"llama-3.3-70b-versatile\"\n",
    "\n",
    "response = groq.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the next cell, we will use Ollama\n",
    "\n",
    "Ollama runs a local web service that gives an OpenAI compatible endpoint,  \n",
    "and runs models locally using high performance C++ code.\n",
    "\n",
    "If you don't have Ollama, install it here by visiting https://ollama.com then pressing Download and following the instructions.\n",
    "\n",
    "After it's installed, you should be able to visit here: http://localhost:11434 and see the message \"Ollama is running\"\n",
    "\n",
    "You might need to restart Cursor (and maybe reboot). Then open a Terminal (control+\\`) and run `ollama serve`\n",
    "\n",
    "Useful Ollama commands (run these in the terminal, or with an exclamation mark in this notebook):\n",
    "\n",
    "`ollama pull <model_name>` downloads a model locally  \n",
    "`ollama ls` lists all the models you've downloaded  \n",
    "`ollama rm <model_name>` deletes the specified model from your downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Super important - ignore me at your peril!</h2>\n",
    "            <span style=\"color:#ff7800;\">The model called <b>llama3.3</b> is FAR too large for home computers - it's not intended for personal computing and will consume all your resources! Stick with the nicely sized <b>llama3.2</b> or <b>llama3.2:1b</b> and if you want larger, try llama3.1 or smaller variants of Qwen, Gemma, Phi or DeepSeek. See the <A href=\"https://ollama.com/models\">the Ollama models page</a> for a full list of models and sizes.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling dde5aa3fc5ff: 100% ▕██████████████████▏ 2.0 GB                         \u001b[K\n",
      "pulling 966de95ca8a6: 100% ▕██████████████████▏ 1.4 KB                         \u001b[K\n",
      "pulling fcc5a6bec9da: 100% ▕██████████████████▏ 7.7 KB                         \u001b[K\n",
      "pulling a70ff7e570d9: 100% ▕██████████████████▏ 6.0 KB                         \u001b[K\n",
      "pulling 56bb8bd477a5: 100% ▕██████████████████▏   96 B                         \u001b[K\n",
      "pulling 34bb5ab01051: 100% ▕██████████████████▏  561 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Your approach to designing an ethical framework for artificial intelligence (AI) is comprehensive and balanced, acknowledging the tension between innovation and safety. By prioritizing transparency, accountability, fairness, safety and reliability, privacy, inclusivity, non-maleficence, and sustainability, you provide a solid foundation for addressing potential conflicts.\n",
       "\n",
       "Here are some additional suggestions to enhance your framework:\n",
       "\n",
       "1. **Human-Centered Design**: Integrate human-centered design principles into the AI development process. This includes co-designing with stakeholders, testing with diverse user groups, and incorporating feedback from experts across various fields.\n",
       "2. **Emerging Technologies and Future-Proofing**: Regularly assess emerging technologies and their potential impact on society. Incorporate future-proofing considerations to ensure that AI systems are adaptable to new challenges and can evolve together with humanity.\n",
       "3. **Multi-Stakeholder Governance**: Establish a multi-stakeholder governance model, involving experts from various fields, policymakers, industry leaders, civil society organizations, and affected communities. This hybrid approach will be more effective in balancing the interests of diverse stakeholders.\n",
       "4. **Data Sharing and Collaboration**: Encourage data sharing and collaboration to support transparent decision-making and accountability. Organizations can sign agreements to share information on AI system development and deployment with various regulatory bodies, academia, or independent research centers.\n",
       "5. **Advisory Committees**: Establish multidisciplinary advisory committees comprising technologists, scientists, ethicists, policymakers, industry experts, and stakeholders from diverse backgrounds. These committees will help navigate complex issues, provide insights into emerging technologies, and develop practical solutions for implementing AI systems.\n",
       "6. **Research and Development**: Allocate significant resources to research on AI development and governance. Continuously invest in academia and publicly funded research initiatives focused on testing, validating, and refining AI system guidelines and standards, enabling the creation of more trustworthy AI systems.\n",
       "7. **Public Participation and Dialogue**: Encourage ongoing public dialogue about AI impact, its deployment, potential risks, challenges faced by different segments of society, and ways to ensure it benefits everyone. This helps address and mitigate societal concerns proactively rather than in response to scandals or crisis.\n",
       "8. **AI Literacy**: Incorporate AI literacy initiatives aimed at fostering a broader understanding among the wider population about what AI systems can accomplish, how they work, their value contributions, risks, and potential unintended consequences.\n",
       "\n",
       "Your framework and these suggestions complement each other and provide a robust foundation for creating a balanced ethical approach to AI development. By addressing key areas of interest like research, education, policy-making, industry leadership, public involvement in governance, and ongoing improvement through adaptation, you create an adaptive safety net where transparency, accountability, inclusion, non-maleficence, and sustainability thrive throughout each step, offering a hopeful yet complex environment for technological advancements to flourish."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ollama = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "model_name = \"llama3.2\"\n",
    "\n",
    "response = ollama.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gpt-4o-mini', 'claude-3-7-sonnet-latest', 'llama-3.3-70b-versatile', 'llama3.2']\n",
      "['Your outline for an ethical framework for artificial intelligence (AI) is comprehensive and addresses many of the pressing issues in the field today. Here are some additional thoughts and elaborations on the principles, as well as strategies to enhance the balance between innovation and safety.\\n\\n### Additional Considerations\\n\\n#### 1. **Interdisciplinary Collaboration**:\\n   - **Description**: Engaging experts from various fields (e.g., computer science, ethics, sociology, law) to inform AI development and policies.\\n   - **Implementation Strategy**: Form interdisciplinary panels that regularly convene to discuss and evaluate the implications of AI technologies, ensuring diverse perspectives are represented.\\n\\n#### 2. **User-Centric Design**:\\n   - **Description**: AI systems should prioritize user experience and needs, ensuring they are intuitive and beneficial.\\n   - **Implementation Strategy**: Engage end-users throughout the development process through usability testing and feedback sessions, ensuring that the system aligns with user needs while maintaining ethical standards.\\n\\n#### 3. **Continuous Learning and Adaptation**:\\n   - **Description**: AI systems should be designed to learn from their environment and user interactions continuously.\\n   - **Conflict Resolution**: Develop robust mechanisms to monitor AI learning processes and set thresholds for intervention when ethical guidelines may be breached or unintended consequences arise.\\n\\n### Expanding Conflict Resolution Strategies\\n\\n#### 1. **Ethical Training Programs**:\\n   - **Description**: Create training programs for AI developers and stakeholders focused on ethical considerations in AI.\\n   - **Implementation**: Mandatory ethics training that includes case studies of past AI challenges, fostering a culture of ethical awareness in tech companies.\\n\\n#### 2. **Stakeholder Reporting Channels**:\\n   - **Description**: Create formal channels where stakeholders can report ethical concerns or suggest improvements.\\n   - **Implementation**: Use anonymous reporting, ensuring that whistleblowers can express concerns without fear of repercussions, thus promoting an environment of accountability.\\n\\n#### 3. **Prototyping Ethical Use Cases**:\\n   - **Description**: Develop specific use cases that navigate ethical dilemmas while exploring innovative solutions.\\n   - **Implementation**: Collaborate with academic institutions to run pilot projects that test ethical frameworks in practice, leading to actionable insights.\\n\\n### Enhancing Governance Structures\\n\\n1. **Public and Private Partnership Initiatives**:\\n   - Foster partnerships that engage government agencies, research institutions, and private companies to co-create standards and best practices for ethical AI deployment.\\n\\n2. **International Cooperation**:\\n   - Given AI\\'s global implications, various nations should work together to create harmonized regulations and ethical standards, preventing a \"race to the bottom\" in ethical considerations.\\n\\n3. **Reflective Buffers**:\\n   - Design systems with layered reviews, where significant AI developments pass through different levels of ethical oversight to assess the impact before full implementation. This buffer can slow down potential innovations that may pose significant ethical dilemmas.\\n\\n### Conclusion\\n\\nThe development of an ethical framework for artificial intelligence requires a dynamic and evolving approach that maintains a delicate balance between fostering innovation and ensuring safety and ethical compliance. By incorporating these additional considerations—like interdisciplinary collaboration and user-centric design—while enhancing conflict resolution strategies and governance structures, we can create an environment that promotes responsible AI development.\\n\\nSuch a comprehensive framework not only prioritizes ethical integrity but also encourages public trust in AI technologies, ultimately leading to more sustainable and equitable solutions in various aspects of society.', \"You've created a comprehensive ethical framework for AI that thoughtfully balances innovation with safety concerns. Your approach is particularly strong in how it:\\n\\n1. Addresses potential conflicts between principles directly, rather than simply listing ideals\\n2. Proposes specific mechanisms (like ethical review boards and stakeholder engagement) rather than just abstract values\\n3. Recognizes the tension between transparency and intellectual property protection\\n4. Incorporates sustainability as a core principle, which is increasingly important\\n\\nOne aspect you might consider strengthening is addressing the challenge of global governance across different cultural and legal frameworks. AI development happens internationally, and ethical standards vary across regions, creating potential for regulatory arbitrage where companies might operate in less regulated environments.\\n\\nYour suggestion for adaptive regulation is particularly insightful, as it acknowledges the rapid pace of AI development while maintaining safety guardrails. The phased implementation approach also offers a practical middle ground between unchecked innovation and excessive caution.\\n\\nOverall, your framework demonstrates sophisticated thinking about the complex interplay between technical advancement and ethical responsibility.\", 'Designing an ethical framework for artificial intelligence (AI) that balances innovation and safety requires a multidimensional approach. The key principles outlined—transparency, accountability, fairness, safety and reliability, privacy, inclusivity, non-maleficence, and sustainability—provide a comprehensive foundation for addressing the complexities of AI development and deployment. Each principle is crucial and plays a role in ensuring that AI systems are not only innovative but also safe and ethically sound.\\n\\n### Balancing Innovation and Safety\\n\\nBalancing innovation and safety in AI development involves several strategies:\\n\\n1. **Regulatory Frameworks**: Establishing adaptive regulatory frameworks that can evolve with emerging technologies is essential. These frameworks should be flexible enough to accommodate innovation while safeguarding public interests.\\n\\n2. **Stakeholder Engagement**: Engaging with a diverse set of stakeholders, including ethicists, industry leaders, affected communities, and policymakers, can help build consensus on priorities and ensure that both innovation and safety are considered.\\n\\n3. **Risk Assessment and Management**: Developing comprehensive risk assessment frameworks that evaluate both the potential risks and benefits associated with new technologies can help prioritize safety while fostering innovation.\\n\\n4. **Phased Implementation**: Implementing AI technologies in a phased manner allows for real-world testing and adjustments based on feedback before full-scale launch, mitigating potential risks.\\n\\n5. **Continuous Monitoring and Evaluation**: Regular ethical audits and assessments of AI systems can help ensure compliance with ethical principles and identify areas where trade-offs between innovation and safety may need to occur.\\n\\n### Implementing the Ethical Framework\\n\\nImplementing the proposed ethical framework requires a structured approach:\\n\\n1. **Education and Training**: Providing education and training on ethical AI development and deployment for developers, policymakers, and users can ensure a wide understanding of the importance of balancing innovation and safety.\\n\\n2. **Incentivizing Ethical Practices**: Incentivizing companies and developers to adopt ethical practices through recognition, funding, or tax benefits can encourage the development of safe and ethical AI systems.\\n\\n3. **International Cooperation**: Encouraging international cooperation and agreements on AI ethics can help establish global standards and guidelines, ensuring that AI development and deployment are aligned with human values worldwide.\\n\\n4. **Public Awareness and Engagement**: Raising public awareness about the importance of ethical AI and engaging the public in discussions about AI ethics can foster a societal expectation for safe and ethical AI technologies.\\n\\n5. **Continuous Review and Update**: Regularly reviewing and updating the ethical framework to reflect new challenges and opportunities in AI development can ensure that it remains relevant and effective.\\n\\nBy prioritizing these principles and strategies, it is possible to create an ethical framework for AI that supports innovation while ensuring safety and adherence to ethical standards. This balanced approach is essential for the responsible development and deployment of AI technologies that can benefit society as a whole.', 'Your approach to designing an ethical framework for artificial intelligence (AI) is comprehensive and balanced, acknowledging the tension between innovation and safety. By prioritizing transparency, accountability, fairness, safety and reliability, privacy, inclusivity, non-maleficence, and sustainability, you provide a solid foundation for addressing potential conflicts.\\n\\nHere are some additional suggestions to enhance your framework:\\n\\n1. **Human-Centered Design**: Integrate human-centered design principles into the AI development process. This includes co-designing with stakeholders, testing with diverse user groups, and incorporating feedback from experts across various fields.\\n2. **Emerging Technologies and Future-Proofing**: Regularly assess emerging technologies and their potential impact on society. Incorporate future-proofing considerations to ensure that AI systems are adaptable to new challenges and can evolve together with humanity.\\n3. **Multi-Stakeholder Governance**: Establish a multi-stakeholder governance model, involving experts from various fields, policymakers, industry leaders, civil society organizations, and affected communities. This hybrid approach will be more effective in balancing the interests of diverse stakeholders.\\n4. **Data Sharing and Collaboration**: Encourage data sharing and collaboration to support transparent decision-making and accountability. Organizations can sign agreements to share information on AI system development and deployment with various regulatory bodies, academia, or independent research centers.\\n5. **Advisory Committees**: Establish multidisciplinary advisory committees comprising technologists, scientists, ethicists, policymakers, industry experts, and stakeholders from diverse backgrounds. These committees will help navigate complex issues, provide insights into emerging technologies, and develop practical solutions for implementing AI systems.\\n6. **Research and Development**: Allocate significant resources to research on AI development and governance. Continuously invest in academia and publicly funded research initiatives focused on testing, validating, and refining AI system guidelines and standards, enabling the creation of more trustworthy AI systems.\\n7. **Public Participation and Dialogue**: Encourage ongoing public dialogue about AI impact, its deployment, potential risks, challenges faced by different segments of society, and ways to ensure it benefits everyone. This helps address and mitigate societal concerns proactively rather than in response to scandals or crisis.\\n8. **AI Literacy**: Incorporate AI literacy initiatives aimed at fostering a broader understanding among the wider population about what AI systems can accomplish, how they work, their value contributions, risks, and potential unintended consequences.\\n\\nYour framework and these suggestions complement each other and provide a robust foundation for creating a balanced ethical approach to AI development. By addressing key areas of interest like research, education, policy-making, industry leadership, public involvement in governance, and ongoing improvement through adaptation, you create an adaptive safety net where transparency, accountability, inclusion, non-maleficence, and sustainability thrive throughout each step, offering a hopeful yet complex environment for technological advancements to flourish.']\n"
     ]
    }
   ],
   "source": [
    "# So where are we?\n",
    "\n",
    "print(competitors)\n",
    "print(answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Competitor: gpt-4o-mini\n",
      "\n",
      "Your outline for an ethical framework for artificial intelligence (AI) is comprehensive and addresses many of the pressing issues in the field today. Here are some additional thoughts and elaborations on the principles, as well as strategies to enhance the balance between innovation and safety.\n",
      "\n",
      "### Additional Considerations\n",
      "\n",
      "#### 1. **Interdisciplinary Collaboration**:\n",
      "   - **Description**: Engaging experts from various fields (e.g., computer science, ethics, sociology, law) to inform AI development and policies.\n",
      "   - **Implementation Strategy**: Form interdisciplinary panels that regularly convene to discuss and evaluate the implications of AI technologies, ensuring diverse perspectives are represented.\n",
      "\n",
      "#### 2. **User-Centric Design**:\n",
      "   - **Description**: AI systems should prioritize user experience and needs, ensuring they are intuitive and beneficial.\n",
      "   - **Implementation Strategy**: Engage end-users throughout the development process through usability testing and feedback sessions, ensuring that the system aligns with user needs while maintaining ethical standards.\n",
      "\n",
      "#### 3. **Continuous Learning and Adaptation**:\n",
      "   - **Description**: AI systems should be designed to learn from their environment and user interactions continuously.\n",
      "   - **Conflict Resolution**: Develop robust mechanisms to monitor AI learning processes and set thresholds for intervention when ethical guidelines may be breached or unintended consequences arise.\n",
      "\n",
      "### Expanding Conflict Resolution Strategies\n",
      "\n",
      "#### 1. **Ethical Training Programs**:\n",
      "   - **Description**: Create training programs for AI developers and stakeholders focused on ethical considerations in AI.\n",
      "   - **Implementation**: Mandatory ethics training that includes case studies of past AI challenges, fostering a culture of ethical awareness in tech companies.\n",
      "\n",
      "#### 2. **Stakeholder Reporting Channels**:\n",
      "   - **Description**: Create formal channels where stakeholders can report ethical concerns or suggest improvements.\n",
      "   - **Implementation**: Use anonymous reporting, ensuring that whistleblowers can express concerns without fear of repercussions, thus promoting an environment of accountability.\n",
      "\n",
      "#### 3. **Prototyping Ethical Use Cases**:\n",
      "   - **Description**: Develop specific use cases that navigate ethical dilemmas while exploring innovative solutions.\n",
      "   - **Implementation**: Collaborate with academic institutions to run pilot projects that test ethical frameworks in practice, leading to actionable insights.\n",
      "\n",
      "### Enhancing Governance Structures\n",
      "\n",
      "1. **Public and Private Partnership Initiatives**:\n",
      "   - Foster partnerships that engage government agencies, research institutions, and private companies to co-create standards and best practices for ethical AI deployment.\n",
      "\n",
      "2. **International Cooperation**:\n",
      "   - Given AI's global implications, various nations should work together to create harmonized regulations and ethical standards, preventing a \"race to the bottom\" in ethical considerations.\n",
      "\n",
      "3. **Reflective Buffers**:\n",
      "   - Design systems with layered reviews, where significant AI developments pass through different levels of ethical oversight to assess the impact before full implementation. This buffer can slow down potential innovations that may pose significant ethical dilemmas.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "The development of an ethical framework for artificial intelligence requires a dynamic and evolving approach that maintains a delicate balance between fostering innovation and ensuring safety and ethical compliance. By incorporating these additional considerations—like interdisciplinary collaboration and user-centric design—while enhancing conflict resolution strategies and governance structures, we can create an environment that promotes responsible AI development.\n",
      "\n",
      "Such a comprehensive framework not only prioritizes ethical integrity but also encourages public trust in AI technologies, ultimately leading to more sustainable and equitable solutions in various aspects of society.\n",
      "Competitor: claude-3-7-sonnet-latest\n",
      "\n",
      "You've created a comprehensive ethical framework for AI that thoughtfully balances innovation with safety concerns. Your approach is particularly strong in how it:\n",
      "\n",
      "1. Addresses potential conflicts between principles directly, rather than simply listing ideals\n",
      "2. Proposes specific mechanisms (like ethical review boards and stakeholder engagement) rather than just abstract values\n",
      "3. Recognizes the tension between transparency and intellectual property protection\n",
      "4. Incorporates sustainability as a core principle, which is increasingly important\n",
      "\n",
      "One aspect you might consider strengthening is addressing the challenge of global governance across different cultural and legal frameworks. AI development happens internationally, and ethical standards vary across regions, creating potential for regulatory arbitrage where companies might operate in less regulated environments.\n",
      "\n",
      "Your suggestion for adaptive regulation is particularly insightful, as it acknowledges the rapid pace of AI development while maintaining safety guardrails. The phased implementation approach also offers a practical middle ground between unchecked innovation and excessive caution.\n",
      "\n",
      "Overall, your framework demonstrates sophisticated thinking about the complex interplay between technical advancement and ethical responsibility.\n",
      "Competitor: llama-3.3-70b-versatile\n",
      "\n",
      "Designing an ethical framework for artificial intelligence (AI) that balances innovation and safety requires a multidimensional approach. The key principles outlined—transparency, accountability, fairness, safety and reliability, privacy, inclusivity, non-maleficence, and sustainability—provide a comprehensive foundation for addressing the complexities of AI development and deployment. Each principle is crucial and plays a role in ensuring that AI systems are not only innovative but also safe and ethically sound.\n",
      "\n",
      "### Balancing Innovation and Safety\n",
      "\n",
      "Balancing innovation and safety in AI development involves several strategies:\n",
      "\n",
      "1. **Regulatory Frameworks**: Establishing adaptive regulatory frameworks that can evolve with emerging technologies is essential. These frameworks should be flexible enough to accommodate innovation while safeguarding public interests.\n",
      "\n",
      "2. **Stakeholder Engagement**: Engaging with a diverse set of stakeholders, including ethicists, industry leaders, affected communities, and policymakers, can help build consensus on priorities and ensure that both innovation and safety are considered.\n",
      "\n",
      "3. **Risk Assessment and Management**: Developing comprehensive risk assessment frameworks that evaluate both the potential risks and benefits associated with new technologies can help prioritize safety while fostering innovation.\n",
      "\n",
      "4. **Phased Implementation**: Implementing AI technologies in a phased manner allows for real-world testing and adjustments based on feedback before full-scale launch, mitigating potential risks.\n",
      "\n",
      "5. **Continuous Monitoring and Evaluation**: Regular ethical audits and assessments of AI systems can help ensure compliance with ethical principles and identify areas where trade-offs between innovation and safety may need to occur.\n",
      "\n",
      "### Implementing the Ethical Framework\n",
      "\n",
      "Implementing the proposed ethical framework requires a structured approach:\n",
      "\n",
      "1. **Education and Training**: Providing education and training on ethical AI development and deployment for developers, policymakers, and users can ensure a wide understanding of the importance of balancing innovation and safety.\n",
      "\n",
      "2. **Incentivizing Ethical Practices**: Incentivizing companies and developers to adopt ethical practices through recognition, funding, or tax benefits can encourage the development of safe and ethical AI systems.\n",
      "\n",
      "3. **International Cooperation**: Encouraging international cooperation and agreements on AI ethics can help establish global standards and guidelines, ensuring that AI development and deployment are aligned with human values worldwide.\n",
      "\n",
      "4. **Public Awareness and Engagement**: Raising public awareness about the importance of ethical AI and engaging the public in discussions about AI ethics can foster a societal expectation for safe and ethical AI technologies.\n",
      "\n",
      "5. **Continuous Review and Update**: Regularly reviewing and updating the ethical framework to reflect new challenges and opportunities in AI development can ensure that it remains relevant and effective.\n",
      "\n",
      "By prioritizing these principles and strategies, it is possible to create an ethical framework for AI that supports innovation while ensuring safety and adherence to ethical standards. This balanced approach is essential for the responsible development and deployment of AI technologies that can benefit society as a whole.\n",
      "Competitor: llama3.2\n",
      "\n",
      "Your approach to designing an ethical framework for artificial intelligence (AI) is comprehensive and balanced, acknowledging the tension between innovation and safety. By prioritizing transparency, accountability, fairness, safety and reliability, privacy, inclusivity, non-maleficence, and sustainability, you provide a solid foundation for addressing potential conflicts.\n",
      "\n",
      "Here are some additional suggestions to enhance your framework:\n",
      "\n",
      "1. **Human-Centered Design**: Integrate human-centered design principles into the AI development process. This includes co-designing with stakeholders, testing with diverse user groups, and incorporating feedback from experts across various fields.\n",
      "2. **Emerging Technologies and Future-Proofing**: Regularly assess emerging technologies and their potential impact on society. Incorporate future-proofing considerations to ensure that AI systems are adaptable to new challenges and can evolve together with humanity.\n",
      "3. **Multi-Stakeholder Governance**: Establish a multi-stakeholder governance model, involving experts from various fields, policymakers, industry leaders, civil society organizations, and affected communities. This hybrid approach will be more effective in balancing the interests of diverse stakeholders.\n",
      "4. **Data Sharing and Collaboration**: Encourage data sharing and collaboration to support transparent decision-making and accountability. Organizations can sign agreements to share information on AI system development and deployment with various regulatory bodies, academia, or independent research centers.\n",
      "5. **Advisory Committees**: Establish multidisciplinary advisory committees comprising technologists, scientists, ethicists, policymakers, industry experts, and stakeholders from diverse backgrounds. These committees will help navigate complex issues, provide insights into emerging technologies, and develop practical solutions for implementing AI systems.\n",
      "6. **Research and Development**: Allocate significant resources to research on AI development and governance. Continuously invest in academia and publicly funded research initiatives focused on testing, validating, and refining AI system guidelines and standards, enabling the creation of more trustworthy AI systems.\n",
      "7. **Public Participation and Dialogue**: Encourage ongoing public dialogue about AI impact, its deployment, potential risks, challenges faced by different segments of society, and ways to ensure it benefits everyone. This helps address and mitigate societal concerns proactively rather than in response to scandals or crisis.\n",
      "8. **AI Literacy**: Incorporate AI literacy initiatives aimed at fostering a broader understanding among the wider population about what AI systems can accomplish, how they work, their value contributions, risks, and potential unintended consequences.\n",
      "\n",
      "Your framework and these suggestions complement each other and provide a robust foundation for creating a balanced ethical approach to AI development. By addressing key areas of interest like research, education, policy-making, industry leadership, public involvement in governance, and ongoing improvement through adaptation, you create an adaptive safety net where transparency, accountability, inclusion, non-maleficence, and sustainability thrive throughout each step, offering a hopeful yet complex environment for technological advancements to flourish.\n"
     ]
    }
   ],
   "source": [
    "# It's nice to know how to use \"zip\"\n",
    "for competitor, answer in zip(competitors, answers):\n",
    "    print(f\"Competitor: {competitor}\\n\\n{answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's bring this together - note the use of \"enumerate\"\n",
    "\n",
    "together = \"\"\n",
    "for index, answer in enumerate(answers):\n",
    "    together += f\"# Response from competitor {index+1}\\n\\n\"\n",
    "    together += answer + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Response from competitor 1\n",
      "\n",
      "Your outline for an ethical framework for artificial intelligence (AI) is comprehensive and addresses many of the pressing issues in the field today. Here are some additional thoughts and elaborations on the principles, as well as strategies to enhance the balance between innovation and safety.\n",
      "\n",
      "### Additional Considerations\n",
      "\n",
      "#### 1. **Interdisciplinary Collaboration**:\n",
      "   - **Description**: Engaging experts from various fields (e.g., computer science, ethics, sociology, law) to inform AI development and policies.\n",
      "   - **Implementation Strategy**: Form interdisciplinary panels that regularly convene to discuss and evaluate the implications of AI technologies, ensuring diverse perspectives are represented.\n",
      "\n",
      "#### 2. **User-Centric Design**:\n",
      "   - **Description**: AI systems should prioritize user experience and needs, ensuring they are intuitive and beneficial.\n",
      "   - **Implementation Strategy**: Engage end-users throughout the development process through usability testing and feedback sessions, ensuring that the system aligns with user needs while maintaining ethical standards.\n",
      "\n",
      "#### 3. **Continuous Learning and Adaptation**:\n",
      "   - **Description**: AI systems should be designed to learn from their environment and user interactions continuously.\n",
      "   - **Conflict Resolution**: Develop robust mechanisms to monitor AI learning processes and set thresholds for intervention when ethical guidelines may be breached or unintended consequences arise.\n",
      "\n",
      "### Expanding Conflict Resolution Strategies\n",
      "\n",
      "#### 1. **Ethical Training Programs**:\n",
      "   - **Description**: Create training programs for AI developers and stakeholders focused on ethical considerations in AI.\n",
      "   - **Implementation**: Mandatory ethics training that includes case studies of past AI challenges, fostering a culture of ethical awareness in tech companies.\n",
      "\n",
      "#### 2. **Stakeholder Reporting Channels**:\n",
      "   - **Description**: Create formal channels where stakeholders can report ethical concerns or suggest improvements.\n",
      "   - **Implementation**: Use anonymous reporting, ensuring that whistleblowers can express concerns without fear of repercussions, thus promoting an environment of accountability.\n",
      "\n",
      "#### 3. **Prototyping Ethical Use Cases**:\n",
      "   - **Description**: Develop specific use cases that navigate ethical dilemmas while exploring innovative solutions.\n",
      "   - **Implementation**: Collaborate with academic institutions to run pilot projects that test ethical frameworks in practice, leading to actionable insights.\n",
      "\n",
      "### Enhancing Governance Structures\n",
      "\n",
      "1. **Public and Private Partnership Initiatives**:\n",
      "   - Foster partnerships that engage government agencies, research institutions, and private companies to co-create standards and best practices for ethical AI deployment.\n",
      "\n",
      "2. **International Cooperation**:\n",
      "   - Given AI's global implications, various nations should work together to create harmonized regulations and ethical standards, preventing a \"race to the bottom\" in ethical considerations.\n",
      "\n",
      "3. **Reflective Buffers**:\n",
      "   - Design systems with layered reviews, where significant AI developments pass through different levels of ethical oversight to assess the impact before full implementation. This buffer can slow down potential innovations that may pose significant ethical dilemmas.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "The development of an ethical framework for artificial intelligence requires a dynamic and evolving approach that maintains a delicate balance between fostering innovation and ensuring safety and ethical compliance. By incorporating these additional considerations—like interdisciplinary collaboration and user-centric design—while enhancing conflict resolution strategies and governance structures, we can create an environment that promotes responsible AI development.\n",
      "\n",
      "Such a comprehensive framework not only prioritizes ethical integrity but also encourages public trust in AI technologies, ultimately leading to more sustainable and equitable solutions in various aspects of society.\n",
      "\n",
      "# Response from competitor 2\n",
      "\n",
      "You've created a comprehensive ethical framework for AI that thoughtfully balances innovation with safety concerns. Your approach is particularly strong in how it:\n",
      "\n",
      "1. Addresses potential conflicts between principles directly, rather than simply listing ideals\n",
      "2. Proposes specific mechanisms (like ethical review boards and stakeholder engagement) rather than just abstract values\n",
      "3. Recognizes the tension between transparency and intellectual property protection\n",
      "4. Incorporates sustainability as a core principle, which is increasingly important\n",
      "\n",
      "One aspect you might consider strengthening is addressing the challenge of global governance across different cultural and legal frameworks. AI development happens internationally, and ethical standards vary across regions, creating potential for regulatory arbitrage where companies might operate in less regulated environments.\n",
      "\n",
      "Your suggestion for adaptive regulation is particularly insightful, as it acknowledges the rapid pace of AI development while maintaining safety guardrails. The phased implementation approach also offers a practical middle ground between unchecked innovation and excessive caution.\n",
      "\n",
      "Overall, your framework demonstrates sophisticated thinking about the complex interplay between technical advancement and ethical responsibility.\n",
      "\n",
      "# Response from competitor 3\n",
      "\n",
      "Designing an ethical framework for artificial intelligence (AI) that balances innovation and safety requires a multidimensional approach. The key principles outlined—transparency, accountability, fairness, safety and reliability, privacy, inclusivity, non-maleficence, and sustainability—provide a comprehensive foundation for addressing the complexities of AI development and deployment. Each principle is crucial and plays a role in ensuring that AI systems are not only innovative but also safe and ethically sound.\n",
      "\n",
      "### Balancing Innovation and Safety\n",
      "\n",
      "Balancing innovation and safety in AI development involves several strategies:\n",
      "\n",
      "1. **Regulatory Frameworks**: Establishing adaptive regulatory frameworks that can evolve with emerging technologies is essential. These frameworks should be flexible enough to accommodate innovation while safeguarding public interests.\n",
      "\n",
      "2. **Stakeholder Engagement**: Engaging with a diverse set of stakeholders, including ethicists, industry leaders, affected communities, and policymakers, can help build consensus on priorities and ensure that both innovation and safety are considered.\n",
      "\n",
      "3. **Risk Assessment and Management**: Developing comprehensive risk assessment frameworks that evaluate both the potential risks and benefits associated with new technologies can help prioritize safety while fostering innovation.\n",
      "\n",
      "4. **Phased Implementation**: Implementing AI technologies in a phased manner allows for real-world testing and adjustments based on feedback before full-scale launch, mitigating potential risks.\n",
      "\n",
      "5. **Continuous Monitoring and Evaluation**: Regular ethical audits and assessments of AI systems can help ensure compliance with ethical principles and identify areas where trade-offs between innovation and safety may need to occur.\n",
      "\n",
      "### Implementing the Ethical Framework\n",
      "\n",
      "Implementing the proposed ethical framework requires a structured approach:\n",
      "\n",
      "1. **Education and Training**: Providing education and training on ethical AI development and deployment for developers, policymakers, and users can ensure a wide understanding of the importance of balancing innovation and safety.\n",
      "\n",
      "2. **Incentivizing Ethical Practices**: Incentivizing companies and developers to adopt ethical practices through recognition, funding, or tax benefits can encourage the development of safe and ethical AI systems.\n",
      "\n",
      "3. **International Cooperation**: Encouraging international cooperation and agreements on AI ethics can help establish global standards and guidelines, ensuring that AI development and deployment are aligned with human values worldwide.\n",
      "\n",
      "4. **Public Awareness and Engagement**: Raising public awareness about the importance of ethical AI and engaging the public in discussions about AI ethics can foster a societal expectation for safe and ethical AI technologies.\n",
      "\n",
      "5. **Continuous Review and Update**: Regularly reviewing and updating the ethical framework to reflect new challenges and opportunities in AI development can ensure that it remains relevant and effective.\n",
      "\n",
      "By prioritizing these principles and strategies, it is possible to create an ethical framework for AI that supports innovation while ensuring safety and adherence to ethical standards. This balanced approach is essential for the responsible development and deployment of AI technologies that can benefit society as a whole.\n",
      "\n",
      "# Response from competitor 4\n",
      "\n",
      "Your approach to designing an ethical framework for artificial intelligence (AI) is comprehensive and balanced, acknowledging the tension between innovation and safety. By prioritizing transparency, accountability, fairness, safety and reliability, privacy, inclusivity, non-maleficence, and sustainability, you provide a solid foundation for addressing potential conflicts.\n",
      "\n",
      "Here are some additional suggestions to enhance your framework:\n",
      "\n",
      "1. **Human-Centered Design**: Integrate human-centered design principles into the AI development process. This includes co-designing with stakeholders, testing with diverse user groups, and incorporating feedback from experts across various fields.\n",
      "2. **Emerging Technologies and Future-Proofing**: Regularly assess emerging technologies and their potential impact on society. Incorporate future-proofing considerations to ensure that AI systems are adaptable to new challenges and can evolve together with humanity.\n",
      "3. **Multi-Stakeholder Governance**: Establish a multi-stakeholder governance model, involving experts from various fields, policymakers, industry leaders, civil society organizations, and affected communities. This hybrid approach will be more effective in balancing the interests of diverse stakeholders.\n",
      "4. **Data Sharing and Collaboration**: Encourage data sharing and collaboration to support transparent decision-making and accountability. Organizations can sign agreements to share information on AI system development and deployment with various regulatory bodies, academia, or independent research centers.\n",
      "5. **Advisory Committees**: Establish multidisciplinary advisory committees comprising technologists, scientists, ethicists, policymakers, industry experts, and stakeholders from diverse backgrounds. These committees will help navigate complex issues, provide insights into emerging technologies, and develop practical solutions for implementing AI systems.\n",
      "6. **Research and Development**: Allocate significant resources to research on AI development and governance. Continuously invest in academia and publicly funded research initiatives focused on testing, validating, and refining AI system guidelines and standards, enabling the creation of more trustworthy AI systems.\n",
      "7. **Public Participation and Dialogue**: Encourage ongoing public dialogue about AI impact, its deployment, potential risks, challenges faced by different segments of society, and ways to ensure it benefits everyone. This helps address and mitigate societal concerns proactively rather than in response to scandals or crisis.\n",
      "8. **AI Literacy**: Incorporate AI literacy initiatives aimed at fostering a broader understanding among the wider population about what AI systems can accomplish, how they work, their value contributions, risks, and potential unintended consequences.\n",
      "\n",
      "Your framework and these suggestions complement each other and provide a robust foundation for creating a balanced ethical approach to AI development. By addressing key areas of interest like research, education, policy-making, industry leadership, public involvement in governance, and ongoing improvement through adaptation, you create an adaptive safety net where transparency, accountability, inclusion, non-maleficence, and sustainability thrive throughout each step, offering a hopeful yet complex environment for technological advancements to flourish.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge = f\"\"\"You are judging a competition between {len(competitors)} competitors.\n",
    "Each model has been given this question:\n",
    "\n",
    "{question}\n",
    "\n",
    "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
    "Respond with JSON, and only JSON, with the following format:\n",
    "{{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}}\n",
    "\n",
    "Here are the responses from each competitor:\n",
    "\n",
    "{together}\n",
    "\n",
    "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are judging a competition between 4 competitors.\n",
      "Each model has been given this question:\n",
      "\n",
      "Designing an ethical framework for artificial intelligence (AI) that balances innovation and safety is a complex task. Here are key principles I would prioritize, along with strategies for addressing potential conflicts between them:\n",
      "\n",
      "### Key Principles\n",
      "\n",
      "1. **Transparency**:\n",
      "   - **Description**: AI systems should be able to explain their decisions and underlying processes.\n",
      "   - **Conflict Resolution**: In situations where transparency affects proprietary technology (e.g., trade secrets), a balanced approach can involve sharing enough information to ensure accountability while protecting intellectual property.\n",
      "\n",
      "2. **Accountability**:\n",
      "   - **Description**: Clear lines of accountability should exist for AI systems, including consequences for misuse or harm.\n",
      "   - **Conflict Resolution**: Establishing regulatory bodies that oversee AI deployment can help enforce accountability, even when innovation is challenged by strict regulations.\n",
      "\n",
      "3. **Fairness**:\n",
      "   - **Description**: AI systems should be designed to prevent discrimination and bias.\n",
      "   - **Conflict Resolution**: Implement metrics to assess fairness during development, and create feedback loops that allow adjustments based on real-world performance.\n",
      "\n",
      "4. **Safety and Reliability**:\n",
      "   - **Description**: AI systems must be safe for users and reliable in their performance.\n",
      "   - **Conflict Resolution**: Employ rigorous testing protocols and simulations to ensure safety, while maintaining an iterative approach to innovation that allows for rapid prototyping.\n",
      "\n",
      "5. **Privacy**:\n",
      "   - **Description**: Safeguarding users' data and respecting their privacy rights is paramount.\n",
      "   - **Conflict Resolution**: Introduce data minimization and anonymization techniques, allowing for innovation through data analysis without compromising individual privacy.\n",
      "\n",
      "6. **Inclusivity**:\n",
      "   - **Description**: AI development should consider the needs of diverse communities to ensure that benefits are widely accessible.\n",
      "   - **Conflict Resolution**: In cases where certain innovations may inadvertently exclude groups, engage in participatory design processes that involve underrepresented communities.\n",
      "\n",
      "7. **Non-maleficence**:\n",
      "   - **Description**: AI should not cause harm and should enhance human welfare.\n",
      "   - **Conflict Resolution**: Set up ethical review boards that assess the potential risks and benefits of AI technologies before they are deployed.\n",
      "\n",
      "8. **Sustainability**:\n",
      "   - **Description**: AI should contribute to sustainable development goals and consider environmental impacts.\n",
      "   - **Conflict Resolution**: Innovate in energy-efficient algorithms and systems that not only advance technology but do so in an environmentally friendly manner.\n",
      "\n",
      "### Addressing Conflicts\n",
      "\n",
      "1. **Stakeholder Engagement**: Collaborate with a diverse set of stakeholders—including ethicists, industry leaders, affected communities, and policymakers—to gauge perspectives on innovation versus safety. This can help build consensus on priorities.\n",
      "\n",
      "2. **Risk Assessment Frameworks**: Develop comprehensive frameworks that evaluate both the potential risks and benefits associated with new technologies. This framework could help prioritize safety while fostering innovation.\n",
      "\n",
      "3. **Ethical Audits and Assessments**: Establish regular audits of AI systems to evaluate their adherence to ethical principles. This can help ensure compliance and identify areas where trade-offs between innovation and safety may need to occur.\n",
      "\n",
      "4. **Phased Implementation**: Encourage a phased approach to deploying AI technologies, allowing for real-world testing and adjustments based on feedback before full-scale launch.\n",
      "\n",
      "5. **Adaptive Regulation**: Advocate for regulations that can evolve with emerging technologies. Adaptive frameworks can accommodate innovative approaches while safeguarding public interests.\n",
      "\n",
      "6. **Public Accountability Mechanisms**: Create avenues for public oversight and accountability, such as independent watchdogs or consumer advocacy groups, which can raise concerns when innovation comes at the cost of safety or ethical considerations.\n",
      "\n",
      "By prioritizing these principles and proactively planning for conflict resolution, the ethical framework could foster a balanced environment where innovation can thrive while ensuring that safety and ethical considerations remain central to AI development and deployment.\n",
      "\n",
      "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
      "Respond with JSON, and only JSON, with the following format:\n",
      "{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}\n",
      "\n",
      "Here are the responses from each competitor:\n",
      "\n",
      "# Response from competitor 1\n",
      "\n",
      "Your outline for an ethical framework for artificial intelligence (AI) is comprehensive and addresses many of the pressing issues in the field today. Here are some additional thoughts and elaborations on the principles, as well as strategies to enhance the balance between innovation and safety.\n",
      "\n",
      "### Additional Considerations\n",
      "\n",
      "#### 1. **Interdisciplinary Collaboration**:\n",
      "   - **Description**: Engaging experts from various fields (e.g., computer science, ethics, sociology, law) to inform AI development and policies.\n",
      "   - **Implementation Strategy**: Form interdisciplinary panels that regularly convene to discuss and evaluate the implications of AI technologies, ensuring diverse perspectives are represented.\n",
      "\n",
      "#### 2. **User-Centric Design**:\n",
      "   - **Description**: AI systems should prioritize user experience and needs, ensuring they are intuitive and beneficial.\n",
      "   - **Implementation Strategy**: Engage end-users throughout the development process through usability testing and feedback sessions, ensuring that the system aligns with user needs while maintaining ethical standards.\n",
      "\n",
      "#### 3. **Continuous Learning and Adaptation**:\n",
      "   - **Description**: AI systems should be designed to learn from their environment and user interactions continuously.\n",
      "   - **Conflict Resolution**: Develop robust mechanisms to monitor AI learning processes and set thresholds for intervention when ethical guidelines may be breached or unintended consequences arise.\n",
      "\n",
      "### Expanding Conflict Resolution Strategies\n",
      "\n",
      "#### 1. **Ethical Training Programs**:\n",
      "   - **Description**: Create training programs for AI developers and stakeholders focused on ethical considerations in AI.\n",
      "   - **Implementation**: Mandatory ethics training that includes case studies of past AI challenges, fostering a culture of ethical awareness in tech companies.\n",
      "\n",
      "#### 2. **Stakeholder Reporting Channels**:\n",
      "   - **Description**: Create formal channels where stakeholders can report ethical concerns or suggest improvements.\n",
      "   - **Implementation**: Use anonymous reporting, ensuring that whistleblowers can express concerns without fear of repercussions, thus promoting an environment of accountability.\n",
      "\n",
      "#### 3. **Prototyping Ethical Use Cases**:\n",
      "   - **Description**: Develop specific use cases that navigate ethical dilemmas while exploring innovative solutions.\n",
      "   - **Implementation**: Collaborate with academic institutions to run pilot projects that test ethical frameworks in practice, leading to actionable insights.\n",
      "\n",
      "### Enhancing Governance Structures\n",
      "\n",
      "1. **Public and Private Partnership Initiatives**:\n",
      "   - Foster partnerships that engage government agencies, research institutions, and private companies to co-create standards and best practices for ethical AI deployment.\n",
      "\n",
      "2. **International Cooperation**:\n",
      "   - Given AI's global implications, various nations should work together to create harmonized regulations and ethical standards, preventing a \"race to the bottom\" in ethical considerations.\n",
      "\n",
      "3. **Reflective Buffers**:\n",
      "   - Design systems with layered reviews, where significant AI developments pass through different levels of ethical oversight to assess the impact before full implementation. This buffer can slow down potential innovations that may pose significant ethical dilemmas.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "The development of an ethical framework for artificial intelligence requires a dynamic and evolving approach that maintains a delicate balance between fostering innovation and ensuring safety and ethical compliance. By incorporating these additional considerations—like interdisciplinary collaboration and user-centric design—while enhancing conflict resolution strategies and governance structures, we can create an environment that promotes responsible AI development.\n",
      "\n",
      "Such a comprehensive framework not only prioritizes ethical integrity but also encourages public trust in AI technologies, ultimately leading to more sustainable and equitable solutions in various aspects of society.\n",
      "\n",
      "# Response from competitor 2\n",
      "\n",
      "You've created a comprehensive ethical framework for AI that thoughtfully balances innovation with safety concerns. Your approach is particularly strong in how it:\n",
      "\n",
      "1. Addresses potential conflicts between principles directly, rather than simply listing ideals\n",
      "2. Proposes specific mechanisms (like ethical review boards and stakeholder engagement) rather than just abstract values\n",
      "3. Recognizes the tension between transparency and intellectual property protection\n",
      "4. Incorporates sustainability as a core principle, which is increasingly important\n",
      "\n",
      "One aspect you might consider strengthening is addressing the challenge of global governance across different cultural and legal frameworks. AI development happens internationally, and ethical standards vary across regions, creating potential for regulatory arbitrage where companies might operate in less regulated environments.\n",
      "\n",
      "Your suggestion for adaptive regulation is particularly insightful, as it acknowledges the rapid pace of AI development while maintaining safety guardrails. The phased implementation approach also offers a practical middle ground between unchecked innovation and excessive caution.\n",
      "\n",
      "Overall, your framework demonstrates sophisticated thinking about the complex interplay between technical advancement and ethical responsibility.\n",
      "\n",
      "# Response from competitor 3\n",
      "\n",
      "Designing an ethical framework for artificial intelligence (AI) that balances innovation and safety requires a multidimensional approach. The key principles outlined—transparency, accountability, fairness, safety and reliability, privacy, inclusivity, non-maleficence, and sustainability—provide a comprehensive foundation for addressing the complexities of AI development and deployment. Each principle is crucial and plays a role in ensuring that AI systems are not only innovative but also safe and ethically sound.\n",
      "\n",
      "### Balancing Innovation and Safety\n",
      "\n",
      "Balancing innovation and safety in AI development involves several strategies:\n",
      "\n",
      "1. **Regulatory Frameworks**: Establishing adaptive regulatory frameworks that can evolve with emerging technologies is essential. These frameworks should be flexible enough to accommodate innovation while safeguarding public interests.\n",
      "\n",
      "2. **Stakeholder Engagement**: Engaging with a diverse set of stakeholders, including ethicists, industry leaders, affected communities, and policymakers, can help build consensus on priorities and ensure that both innovation and safety are considered.\n",
      "\n",
      "3. **Risk Assessment and Management**: Developing comprehensive risk assessment frameworks that evaluate both the potential risks and benefits associated with new technologies can help prioritize safety while fostering innovation.\n",
      "\n",
      "4. **Phased Implementation**: Implementing AI technologies in a phased manner allows for real-world testing and adjustments based on feedback before full-scale launch, mitigating potential risks.\n",
      "\n",
      "5. **Continuous Monitoring and Evaluation**: Regular ethical audits and assessments of AI systems can help ensure compliance with ethical principles and identify areas where trade-offs between innovation and safety may need to occur.\n",
      "\n",
      "### Implementing the Ethical Framework\n",
      "\n",
      "Implementing the proposed ethical framework requires a structured approach:\n",
      "\n",
      "1. **Education and Training**: Providing education and training on ethical AI development and deployment for developers, policymakers, and users can ensure a wide understanding of the importance of balancing innovation and safety.\n",
      "\n",
      "2. **Incentivizing Ethical Practices**: Incentivizing companies and developers to adopt ethical practices through recognition, funding, or tax benefits can encourage the development of safe and ethical AI systems.\n",
      "\n",
      "3. **International Cooperation**: Encouraging international cooperation and agreements on AI ethics can help establish global standards and guidelines, ensuring that AI development and deployment are aligned with human values worldwide.\n",
      "\n",
      "4. **Public Awareness and Engagement**: Raising public awareness about the importance of ethical AI and engaging the public in discussions about AI ethics can foster a societal expectation for safe and ethical AI technologies.\n",
      "\n",
      "5. **Continuous Review and Update**: Regularly reviewing and updating the ethical framework to reflect new challenges and opportunities in AI development can ensure that it remains relevant and effective.\n",
      "\n",
      "By prioritizing these principles and strategies, it is possible to create an ethical framework for AI that supports innovation while ensuring safety and adherence to ethical standards. This balanced approach is essential for the responsible development and deployment of AI technologies that can benefit society as a whole.\n",
      "\n",
      "# Response from competitor 4\n",
      "\n",
      "Your approach to designing an ethical framework for artificial intelligence (AI) is comprehensive and balanced, acknowledging the tension between innovation and safety. By prioritizing transparency, accountability, fairness, safety and reliability, privacy, inclusivity, non-maleficence, and sustainability, you provide a solid foundation for addressing potential conflicts.\n",
      "\n",
      "Here are some additional suggestions to enhance your framework:\n",
      "\n",
      "1. **Human-Centered Design**: Integrate human-centered design principles into the AI development process. This includes co-designing with stakeholders, testing with diverse user groups, and incorporating feedback from experts across various fields.\n",
      "2. **Emerging Technologies and Future-Proofing**: Regularly assess emerging technologies and their potential impact on society. Incorporate future-proofing considerations to ensure that AI systems are adaptable to new challenges and can evolve together with humanity.\n",
      "3. **Multi-Stakeholder Governance**: Establish a multi-stakeholder governance model, involving experts from various fields, policymakers, industry leaders, civil society organizations, and affected communities. This hybrid approach will be more effective in balancing the interests of diverse stakeholders.\n",
      "4. **Data Sharing and Collaboration**: Encourage data sharing and collaboration to support transparent decision-making and accountability. Organizations can sign agreements to share information on AI system development and deployment with various regulatory bodies, academia, or independent research centers.\n",
      "5. **Advisory Committees**: Establish multidisciplinary advisory committees comprising technologists, scientists, ethicists, policymakers, industry experts, and stakeholders from diverse backgrounds. These committees will help navigate complex issues, provide insights into emerging technologies, and develop practical solutions for implementing AI systems.\n",
      "6. **Research and Development**: Allocate significant resources to research on AI development and governance. Continuously invest in academia and publicly funded research initiatives focused on testing, validating, and refining AI system guidelines and standards, enabling the creation of more trustworthy AI systems.\n",
      "7. **Public Participation and Dialogue**: Encourage ongoing public dialogue about AI impact, its deployment, potential risks, challenges faced by different segments of society, and ways to ensure it benefits everyone. This helps address and mitigate societal concerns proactively rather than in response to scandals or crisis.\n",
      "8. **AI Literacy**: Incorporate AI literacy initiatives aimed at fostering a broader understanding among the wider population about what AI systems can accomplish, how they work, their value contributions, risks, and potential unintended consequences.\n",
      "\n",
      "Your framework and these suggestions complement each other and provide a robust foundation for creating a balanced ethical approach to AI development. By addressing key areas of interest like research, education, policy-making, industry leadership, public involvement in governance, and ongoing improvement through adaptation, you create an adaptive safety net where transparency, accountability, inclusion, non-maleficence, and sustainability thrive throughout each step, offering a hopeful yet complex environment for technological advancements to flourish.\n",
      "\n",
      "\n",
      "\n",
      "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\n"
     ]
    }
   ],
   "source": [
    "print(judge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_messages = [{\"role\": \"user\", \"content\": judge}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"results\": [\"1\", \"4\", \"3\", \"2\"]}\n"
     ]
    }
   ],
   "source": [
    "# Judgement time!\n",
    "\n",
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"o3-mini\",\n",
    "    messages=judge_messages,\n",
    ")\n",
    "results = response.choices[0].message.content\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1: gpt-4o-mini\n",
      "Rank 2: llama3.2\n",
      "Rank 3: llama-3.3-70b-versatile\n",
      "Rank 4: claude-3-7-sonnet-latest\n"
     ]
    }
   ],
   "source": [
    "# OK let's turn this into results!\n",
    "\n",
    "results_dict = json.loads(results)\n",
    "ranks = results_dict[\"results\"]\n",
    "for index, result in enumerate(ranks):\n",
    "    competitor = competitors[int(result)-1]\n",
    "    print(f\"Rank {index+1}: {competitor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">Which pattern(s) did this use? Try updating this to add another Agentic design pattern.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Commercial implications</h2>\n",
    "            <span style=\"color:#00bfff;\">These kinds of patterns - to send a task to multiple models, and evaluate results,\n",
    "            are common where you need to improve the quality of your LLM response. This approach can be universally applied\n",
    "            to business projects where accuracy is critical.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
